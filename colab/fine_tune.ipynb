{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f01a03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['# üß† Fine-Tune GPT2 untuk Chatbot Kampus\\n',\n",
       "    'Model ini akan dilatih dengan dataset tanya-jawab kampus berbasis GPT2.']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['!pip install transformers datasets']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## üìÅ Upload File Dataset `qa_kampus.jsonl`']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['from google.colab import files\\n',\n",
       "    'uploaded = files.upload()']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['from datasets import load_dataset\\n',\n",
       "    '\\n',\n",
       "    'dataset = load_dataset(\"json\", data_files=\"qa_kampus.jsonl\")\\n',\n",
       "    'dataset = dataset[\"train\"].train_test_split(test_size=0.1)\\n',\n",
       "    'dataset']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## üîß Load Tokenizer & Model GPT2']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['from transformers import GPT2Tokenizer, GPT2LMHeadModel\\n',\n",
       "    '\\n',\n",
       "    'tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\\n',\n",
       "    'tokenizer.pad_token = tokenizer.eos_token\\n',\n",
       "    '\\n',\n",
       "    'model = GPT2LMHeadModel.from_pretrained(\"gpt2\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## üî† Tokenisasi Dataset']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['def tokenize(example):\\n',\n",
       "    '    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\\n',\n",
       "    '\\n',\n",
       "    'tokenized_dataset = dataset.map(tokenize, batched=True)']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## üèãÔ∏è Fine-Tune GPT2']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['from transformers import Trainer, TrainingArguments\\n',\n",
       "    '\\n',\n",
       "    'training_args = TrainingArguments(\\n',\n",
       "    '    output_dir=\"./results\",\\n',\n",
       "    '    num_train_epochs=3,\\n',\n",
       "    '    per_device_train_batch_size=4,\\n',\n",
       "    '    per_device_eval_batch_size=4,\\n',\n",
       "    '    evaluation_strategy=\"epoch\",\\n',\n",
       "    '    save_strategy=\"epoch\",\\n',\n",
       "    '    save_total_limit=2,\\n',\n",
       "    '    logging_steps=10,\\n',\n",
       "    '    fp16=True\\n',\n",
       "    ')\\n',\n",
       "    '\\n',\n",
       "    'trainer = Trainer(\\n',\n",
       "    '    model=model,\\n',\n",
       "    '    args=training_args,\\n',\n",
       "    '    train_dataset=tokenized_dataset[\"train\"],\\n',\n",
       "    '    eval_dataset=tokenized_dataset[\"test\"],\\n',\n",
       "    '    tokenizer=tokenizer\\n',\n",
       "    ')\\n',\n",
       "    '\\n',\n",
       "    'trainer.train()']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## üíæ Simpan Model & Tokenizer']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['trainer.save_model(\"gpt2-kampus\")\\n',\n",
       "    'tokenizer.save_pretrained(\"gpt2-kampus\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## ‚¨áÔ∏è Download Model ke Laptop']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 0,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['!zip -r gpt2-kampus.zip gpt2-kampus\\n',\n",
       "    'files.download(\"gpt2-kampus.zip\")']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'name': 'python'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# üß† Fine-Tune GPT2 untuk Chatbot Kampus\\n\",\n",
    "    \"Model ini akan dilatih dengan dataset tanya-jawab kampus berbasis GPT2.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"!pip install transformers datasets\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìÅ Upload File Dataset `qa_kampus.jsonl`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from google.colab import files\\n\",\n",
    "    \"uploaded = files.upload()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from datasets import load_dataset\\n\",\n",
    "    \"\\n\",\n",
    "    \"dataset = load_dataset(\\\"json\\\", data_files=\\\"qa_kampus.jsonl\\\")\\n\",\n",
    "    \"dataset = dataset[\\\"train\\\"].train_test_split(test_size=0.1)\\n\",\n",
    "    \"dataset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîß Load Tokenizer & Model GPT2\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from transformers import GPT2Tokenizer, GPT2LMHeadModel\\n\",\n",
    "    \"\\n\",\n",
    "    \"tokenizer = GPT2Tokenizer.from_pretrained(\\\"gpt2\\\")\\n\",\n",
    "    \"tokenizer.pad_token = tokenizer.eos_token\\n\",\n",
    "    \"\\n\",\n",
    "    \"model = GPT2LMHeadModel.from_pretrained(\\\"gpt2\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üî† Tokenisasi Dataset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def tokenize(example):\\n\",\n",
    "    \"    return tokenizer(example[\\\"text\\\"], truncation=True, padding=\\\"max_length\\\", max_length=128)\\n\",\n",
    "    \"\\n\",\n",
    "    \"tokenized_dataset = dataset.map(tokenize, batched=True)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üèãÔ∏è Fine-Tune GPT2\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from transformers import Trainer, TrainingArguments\\n\",\n",
    "    \"\\n\",\n",
    "    \"training_args = TrainingArguments(\\n\",\n",
    "    \"    output_dir=\\\"./results\\\",\\n\",\n",
    "    \"    num_train_epochs=3,\\n\",\n",
    "    \"    per_device_train_batch_size=4,\\n\",\n",
    "    \"    per_device_eval_batch_size=4,\\n\",\n",
    "    \"    evaluation_strategy=\\\"epoch\\\",\\n\",\n",
    "    \"    save_strategy=\\\"epoch\\\",\\n\",\n",
    "    \"    save_total_limit=2,\\n\",\n",
    "    \"    logging_steps=10,\\n\",\n",
    "    \"    fp16=True\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"trainer = Trainer(\\n\",\n",
    "    \"    model=model,\\n\",\n",
    "    \"    args=training_args,\\n\",\n",
    "    \"    train_dataset=tokenized_dataset[\\\"train\\\"],\\n\",\n",
    "    \"    eval_dataset=tokenized_dataset[\\\"test\\\"],\\n\",\n",
    "    \"    tokenizer=tokenizer\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"trainer.train()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üíæ Simpan Model & Tokenizer\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"trainer.save_model(\\\"gpt2-kampus\\\")\\n\",\n",
    "    \"tokenizer.save_pretrained(\\\"gpt2-kampus\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## ‚¨áÔ∏è Download Model ke Laptop\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"!zip -r gpt2-kampus.zip gpt2-kampus\\n\",\n",
    "    \"files.download(\\\"gpt2-kampus.zip\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e1f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
